# Stage III - Predictive Data Analytics Report

## Introduction
This report details Stage III of the big data course project, which focuses on building and evaluating predictive models using Apache Spark's MLlib library. The primary goal was to predict the average job salary (`salary_avg`) using features derived from job descriptions processed in earlier pipeline stages. This involved training, tuning, and comparing Linear Regression and Gradient-Boosted Tree (GBT) Regressor models.

## Data Source
The input data for this stage consisted of preprocessed training and testing datasets stored in HDFS (`project/data/train`, `project/data/test`). These datasets were generated by `scripts/data_predprocessing.py` and contain two main columns:
- `features`: A vector representation combining numerical features, one-hot encoded categoricals, and TF-IDF representations of text data.
- `label`: The target variable, `salary_avg`, transformed using `log1p` for modeling.
Additionally, the original job description data stored in the Hive table `team14_projectdb.job_descriptions_part` was used to enrich the final predictions with original job details.

## Methodology

### 1. Environment Setup and Data Loading (`scripts/ml_modeling.py`)
- A `SparkSession` was configured to run on YARN in client mode, enabling Hive support to access the original data.
- The preprocessed training (`train_data`) and testing (`test_data`) datasets were loaded from HDFS JSON files using a predefined schema (`StructType([StructField("job_id", StringType(), True), StructField("features", VectorUDT(), True), StructField("label", DoubleType(), True)])`) to ensure correct data types, especially for the feature vectors.
- The original job data (`original_df`) was loaded from Hive, selecting necessary columns including `job_id`.
- All three DataFrames (`train_data`, `test_data`, `original_df`) were cached to optimize performance during the subsequent iterative processes.

### 2. Model Training and Hyperparameter Tuning (`scripts/ml_modeling.py`)
Two regression algorithms were employed to predict the log-transformed salary (`label`):

1.  **Linear Regression (`LinearRegression`)**: Chosen as a baseline model.
2.  **Gradient-Boosted Tree Regressor (`GBTRegressor`)**: Chosen for its potential to capture non-linear relationships.

For each algorithm:
- **Model Instantiation**: The regressors were initialized, specifying the `featuresCol` and `labelCol`.
- **Hyperparameter Grid**: `ParamGridBuilder` defined the search space for hyperparameters:
    - *Linear Regression*: `regParam`, `elasticNetParam`, `aggregationDepth`.
    - *GBT Regressor*: `maxDepth`, `maxIter`, `stepSize`.
- **Cross-Validation**: `CrossValidator` was set up with 3 folds (`numFolds=3`) and `RegressionEvaluator` using Root Mean Squared Error (`RMSE`) on the log-scale label as the metric to guide the selection of the best hyperparameter set. The cross-validation was performed on the `train_data`.
- **Best Model Selection**: The `CrossValidator` was fitted (`fit`) to the `train_data`. The model achieving the lowest average RMSE across the folds was selected as the best model (`model1` for Linear Regression, `model2` for GBT).
- **Tuning Results**: The average RMSE achieved for each hyperparameter combination during cross-validation was collected and saved to HDFS as CSV files (`project/output/lr_tuning_results.csv`, `project/output/gbt_tuning_results.csv`).

### 3. Prediction and Evaluation (`scripts/ml_modeling.py`)
- **Prediction**: The best models (`model1`, `model2`) were used to generate predictions (`prediction` column) on the unseen `test_data`. These predictions are on the log-transformed scale.
- **Log-Scale Evaluation**: The performance of each model on the `test_data` was evaluated using `RMSE` and R-squared (`R2`) metrics, calculated on the log-transformed label and predictions. These metrics quantify the model's accuracy on the scale it was trained on.
- **Results Comparison**: The log-scale evaluation metrics (RMSE, R2) for both models were compiled into a DataFrame for comparison.

**Model Performance Comparison (on log-transformed test data):**
```
+------------------+--------------------+--------------------------+
|Model_Type        |RMSE                |R2                        |
+------------------+--------------------+--------------------------+
|LinearRegression  |0.09180878420126459 |-6.045444431723723E-7     |
|GBTRegressor      |0.09180633131218793 |5.282951011942316E-5      |
+------------------+--------------------+--------------------------+
```
*Note: R2 values extremely close to zero indicate that the models explain very little variance in the log-transformed target variable based on the current features.*

- **Inverse Transformation & Enrichment**:
    - Predictions (`prediction`) and original labels (`label`) from the test set were transformed back to the original salary scale using `expm1`.
    - These transformed predictions were joined with the `original_df` using `job_id` to create enriched prediction datasets containing original job details alongside the actual and predicted salaries (`original_salary`, `predicted_salary`).

### 4. Saving Artifacts (`scripts/ml_modeling.py` & `scripts/stage3.sh`)
The following artifacts were generated and saved:
- **Best Models**: The trained `model1` (Linear Regression) and `model2` (GBT) were saved to HDFS (`project/models/model1`, `project/models/model2`).
- **Enriched Predictions**: The test set predictions, joined with original job data and transformed back to the original salary scale, were saved as single-partition CSV files to HDFS (`project/output/model1_predictions.csv`, `project/output/model2_predictions.csv`).
- **Evaluation Metrics**: The log-scale model comparison table (RMSE, R2) was saved as a single-partition CSV file to HDFS (`project/output/evaluation.csv`).
- **Tuning Results**: The hyperparameter tuning results (average RMSE per parameter set) were saved as CSV files to HDFS (`project/output/lr_tuning_results.csv`, `project/output/gbt_tuning_results.csv`).
- **Local Download**: The `scripts/stage3.sh` script orchestrates the download of all these artifacts from HDFS to the local project directories (`models/`, `output/`).

## Automation and Quality (`scripts/stage3.sh`)
- The entire Stage 3 workflow, including data preprocessing (`scripts/data_predprocessing.py`) and ML modeling (`scripts/ml_modeling.py`), is automated via the `scripts/stage3.sh` script.
- The script manages HDFS directory setup and cleanup.
- It executes the Spark jobs using `spark-submit` configured for the YARN cluster.
- It downloads all results from HDFS to the local filesystem.
- It includes `pylint` checks against both Python scripts using the `.pylintrc` configuration to encourage code quality.
- Finally, it empties the HDFS trash for the user.

## Conclusion
Stage III successfully implemented an end-to-end predictive modeling pipeline using Spark ML. Preprocessed data was loaded, two distinct regression models (Linear Regression and GBT) were trained and tuned using 3-fold cross-validation based on log-scale RMSE, and their performance was evaluated on a held-out test set using log-scale RMSE and R2. The best models, detailed tuning results, log-scale performance comparison, and enriched predictions (transformed to the original salary scale) were systematically saved to HDFS and subsequently downloaded locally. The automation provided by `stage3.sh` ensures reproducibility and includes code quality checks. While the pipeline functions correctly, the low R2 values suggest that the current feature set has limited predictive power for salary, warranting further investigation into feature engineering or alternative modeling approaches in future work. 