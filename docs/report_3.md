# Stage III - Predictive Data Analytics Report

## Overview
This report outlines the implementation of Stage III of the big data pipeline project, focusing on predictive data analytics using Apache Spark ML. The objective was to build, train, evaluate, and tune machine learning models to predict the average salary (`salary_avg`) based on the features extracted and processed from the job descriptions dataset in the previous stages.

## Dataset Description
The input for this stage was the preprocessed data generated by `scripts/data_predprocessing.py` and stored in HDFS at `project/data/train` and `project/data/test` as JSON files. Each record contains a `features` vector (resulting from numerical scaling, one-hot encoding, TF-IDF, etc.) and a `label` (the `salary_avg`).

## Implementation Steps

### 1. Data Loading (`scripts/ml_modeling.py`)
- A Spark session was initialized with Hive support enabled.
- The preprocessed training and testing data were loaded from the HDFS JSON files (`project/data/train`, `project/data/test`).
- An explicit schema (`StructType([StructField("features", VectorUDT(), True), StructField("label", DoubleType(), True)])`) was provided during loading to ensure robustness and prevent schema inference issues.
- The loaded DataFrames (`train_data`, `test_data`) were cached for improved performance during iterative model training and tuning.

### 2. ML Modeling (`scripts/ml_modeling.py`)
Two regression models were selected to predict the log-transformed average salary (`log1p(salary_avg)`):

1.  **Linear Regression:** A standard linear model.
2.  **Gradient-Boosted Tree (GBT) Regressor:** An ensemble tree-based model.

For both models, the following steps were performed:

- **Model Initialization:** The respective regressors (`LinearRegression`, `GBTRegressor`) were instantiated with `featuresCol="features"` and `labelCol="label"`.
- **Hyperparameter Tuning Setup:**
    - `ParamGridBuilder` was used to define a grid of hyperparameters to search for each model:
        - *Linear Regression:* `regParam`, `elasticNetParam`, `aggregationDepth`.
        - *GBT Regressor:* `maxDepth`, `maxIter`, `stepSize`.
    - `CrossValidator` was configured to tune the models using 3-fold cross-validation on the `train_data`. `RMSE` was used as the evaluation metric for selecting the best hyperparameters.
- **Training and Best Model Selection:** The `CrossValidator` estimator was fitted to the `train_data` (containing log-transformed labels). The best model found during cross-validation was selected (`model1` for Linear Regression, `model2` for GBT).
- **Prediction:** The best model (`model1`, `model2`) was used to make predictions (on the log scale) on the held-out `test_data`.
- **Evaluation:** The performance of the best model was evaluated *on the log-transformed scale* using both Root Mean Squared Error (`RMSE`) and R-squared (`R2`) metrics via `RegressionEvaluator`. These metrics reflect how well the model performs on the scale it was trained on.
- **Inverse Transformation:** The final predictions were transformed back to the original salary scale using the `expm1` function (inverse of `log1p`).

### 3. Model Comparison (`scripts/ml_modeling.py`)
- The evaluation results (RMSE and R2) for both `model1` and `model2` on the test data *on the log-transformed scale* were collected.
- A Spark DataFrame was created to compare the performance of the two models side-by-side.

**Model Comparison Results (on log-transformed scale):**
```
+------------------+------------------+--------------------+
|Model_Type        |RMSE              |R2                  |
+------------------+------------------+--------------------+
|LinearRegression  |7529.813526064228 |3.497925155993009E-5|
|GBTRegressor      |7529.786017965478 |4.228543150641695E-5|
+------------------+------------------+--------------------+
```

The results show very similar performance between the tuned Linear Regression and GBT models on the test set, with GBT having a slightly lower RMSE and slightly higher R2, though the R2 values are extremely close to zero, suggesting neither model explains much of the variance in the target variable with the current feature set and preprocessing.

### 4. Saving Models and Results (`scripts/ml_modeling.py` & `scripts/stage3.sh`)
- The best trained models (`model1`, `model2`) were saved to HDFS in the `project/models/` directory (`model1`, `model2`).
- The predictions generated by each model on the test data, *and the corresponding actual labels*, were transformed back to the original salary scale using `expm1` and saved as single-partition CSV files (with headers) to HDFS in `project/output/` (`model1_predictions.csv`, `model2_predictions.csv`).
- The model comparison DataFrame (containing log-scale evaluation metrics) was saved as a single-partition CSV file (with headers) to HDFS in `project/output/evaluation.csv`.
- The hyperparameter tuning results for each model (average RMSE per parameter set on the log scale) were saved to HDFS (`lr_tuning_results.csv`, `gbt_tuning_results.csv`).
- The `stage3.sh` script handles downloading these artifacts from HDFS to the local `models/`, `output/`, and `data/` directories after the Spark jobs complete.

### 5. Automation and Quality Check (`scripts/stage3.sh`)
- The entire Stage 3 process (preprocessing and modeling) is automated by the `scripts/stage3.sh` script.
- It ensures the necessary HDFS directories are created and cleaned.
- It executes the `data_predprocessing.py` and `ml_modeling.py` scripts using `spark-submit` configured for the YARN cluster.
- It downloads all necessary outputs (data, models, predictions, evaluation) from HDFS to the local project structure.
- Includes `pylint` checks (using `.pylintrc`) for both Python scripts involved in this stage to ensure code quality.

## Technical Choices

### Hyperparameter Tuning: CrossValidator
- `CrossValidator` with `numFolds=3` was used for hyperparameter tuning as required.
- It performs K-fold cross-validation (here, 3 folds) by splitting the training data into K smaller sets.
- For each hyperparameter combination, it trains on K-1 folds and validates on the remaining fold.
- The performance metric (RMSE) is averaged across the folds for each parameter combination.
- The parameters yielding the best average performance are chosen.
- This approach provides a more robust estimate of model performance on unseen data compared to a single train-validation split, albeit at a higher computational cost.

### Evaluation Metrics: RMSE and R2
- **RMSE (Root Mean Squared Error):** Provides a measure of the average magnitude of the prediction errors *on the log-transformed salary scale*. Lower is better.
- **R2 (R-squared):** Indicates the proportion of the variance in the *log-transformed salary* that is predictable from the features. A value closer to 1 indicates a better fit on the log scale.

### Models: Linear Regression & GBTRegressor
- **Linear Regression:** Chosen as a baseline model due to its simplicity, interpretability, and computational efficiency.
- **GBTRegressor:** Selected as a more complex, potentially higher-performing model. Gradient Boosting builds trees sequentially, with each new tree trying to correct the errors of the previous ones, often leading to good predictive accuracy.

## Conclusion
Stage III successfully implemented a predictive modeling pipeline using Spark ML. It loaded preprocessed data (with log-transformed salaries), trained and tuned both Linear Regression and GBT Regressor models using 3-fold Cross-Validation to predict log-transformed salaries, evaluated their performance on the log scale using a held-out test set, and compared the results. The best models, their predictions (transformed back to the original salary scale), the log-scale evaluation comparison, and hyperparameter tuning details were saved to HDFS and subsequently downloaded locally. The entire process is automated via the `stage3.sh` script, including code quality checks with Pylint and HDFS trash cleanup. While the models' predictive performance (indicated by low R2 values on the log scale) suggests further feature engineering or model exploration might be needed, the pipeline itself fulfills the requirements of this stage. 